import os
import json
import pandas as pd
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import accuracy_score
import numpy as np

def get_validation_data(df):
    """ Get validation dataset and its labels"""
    labeles = df.label
    text = df.text
    return (text, labeles)

def l2f(l, output_file_path):
    """ Save list as file"""
    f = open(output_file_path, "w+")
    [f.write(str(item)+"\n") for item in l]
    f.close()
def get_commons(l1, l2):
    com = list(set(l1).intersection(l2))
    return com

def f2l( file):
        file_input = open(file, "r", errors="ignore")
        file_lines = file_input.readlines()
        list_of_file = []
        [list_of_file.append(item.strip()) for item in file_lines]
        file_input.close()
        return list_of_file

def exclude(target, junk):
        netlist = []
        [netlist.append(item) for item in target if item not in junk]
        return netlist

def dic_info(dic):
    for item in dic:
        history = dic[item]
        print("{}: {}".format(item, len(history['cves'])))

def remove_items_from_list(_list_, items):
    for item in items:
        _list_.remove(item)
    return _list_

def remove_items_from_dic(dic, to_remove_items, keys=None):
    """Remove a list of items from dictionnary"""
    if keys is not None:
        for key in keys:
            key_cves = dic[key]['cves']
            # walk through items to be removed
            for item in to_remove_items:
                if item in key_cves:
                    key_cves.remove(item)
        return dic
    else:
        for name, value in dic.items():
            cves = value['cves']
            for cve in to_remove_items:
                if cve in cves:
                    cves.remove(cve)
        return dic


def get_cves_by_dic(dic, meta_data):
    """ Get a specific amount of CVEs"""
    cves_list = []
    for num, keys in meta_data.items():
        if(type(keys) is list):
            for key in keys:
                items_to_remove = []
                cves = dic[key]['cves']
                for i in range(num):
                    cves_list.append(cves[i])
                    items_to_remove.append(cves[i])
                remove_items_from_list(cves, items_to_remove)
        else:
            items_to_remove = []
            cves = dic[keys]['cves']
            for i in range(num):
                cves_list.append(cves[i])
                items_to_remove.append(cves[i])
            remove_items_from_list(cves, items_to_remove)
    return cves_list, dic

def get_cves_by_keys(dic, keys):
    """ Get all CVEs from specified keys"""
    list_of_cves = []
    for key in keys:
        cves = dic[key]['cves']
        list_of_cves.extend(cves)
    return list_of_cves

def save_as_json(dic, path, file_name):
    if os.path.isdir(path):
        abs_path = os.path.join(path, file_name)
    else:
        os.mkdir(path)
        abs_path = os.path.join(path, file_name)

    output_file = open(abs_path+'.json', "w+")
    json.dump(dic, output_file)

def adjust_variation(input_file, max):
    dataset = []
    for items in input_file:
        if len(input_file[items]['cves']) <= max:
            for item in input_file[items]['cves']:
                dataset.append(item)
        else:
            for i in range(0, max):
                dataset.append(input_file[items]['cves'][i])
    return dataset

def concat_csv(csv_list):
    print("[+] Concatination...")
    concatenated_df = pd.concat(csv_list)
    print("[+] done")
    return concatenated_df

def save_predictions(path, espreds, nespreds, uncertainpreds):
    predictions = open(path, "w+")
    predictions.write("Uncertain = "+str(len(uncertainpreds['text']))+"\n")
    predictions.write("ES = "+str(len(espreds['text']))+"\n")
    predictions.write("ES | ESL = "+str(espreds['label'].count(0))+"\n")
    predictions.write("ES | NESL = "+str(espreds['label'].count(1))+"\n")
    predictions.write("NES = "+str(len(nespreds['text']))+"\n")
    predictions.write("NES | ESL = "+str(nespreds['label'].count(0))+"\n")
    predictions.write("NES | NESL = "+str(nespreds['label'].count(1)))
    predictions.close()

def dataset_selection(es_df, nes_df, unce_df):
    # Select samples labeled as ES
    es_bar = es_df[es_df.label == 1]
    
    # Select samples labeled as NES
    nes_bar = nes_df[nes_df.label == 0]

    # Calculate 20% of ES samples
    es_20_percent = int((len(es_bar.label) * 20) / 100)

    # Calculate 20% of NES samples
    nes_20_percent = int((len(nes_bar.label) * 20) / 100)

    # Shuffle the uncertain samples
    unce_df = unce_df.sample(frac=1)

    # Split ES samples into 20% and 80%
    #es_df_20_percent = es_bar.head(es_20_percent)
    es_df_80_percent = es_bar.tail(-es_20_percent)

    # Split NES samples into 20% and 80%
    #nes_df_20_percent = nes_bar.head(nes_20_percent)
    nes_df_80_percent = nes_bar.tail(-nes_20_percent)

    # Merge tables for 80% uncertain samples
    uncertain = pd.concat([es_df_80_percent, nes_df_80_percent, unce_df])

    return uncertain



def dic_to_df(dic):
    dic_to_df = pd.DataFrame({'text':dic['text'], 'label':dic['label']})
    return dic_to_df

def save_to_excel(y_pred, y_test, path):
    accuracy = accuracy_score(y_test, np.argmax(y_pred, axis=1))
    precision = precision_score(y_test, np.argmax(y_pred, axis=1), average='macro')
    recall = recall_score(y_test, np.argmax(y_pred, axis=1), average='macro')
    f1 = f1_score(y_test, np.argmax(y_pred, axis=1), average='macro')
    models_dataframe = pd.DataFrame({'Models':"LSTM",'Accuracy':[accuracy*100] ,'Precesion':[precision*100], 'Recall':[recall*100],
                            'F1-score': [f1*100]})
    models_dataframe.set_index('Models', inplace = True)
    #models_dataframe.sort_values(by = ['Accuracy'], ascending=False)
    models_dataframe.to_excel(path+'.xlsx', header=True, index=True)

def save_metrics_generalization(tp, tn, fp, fn, path):
    f1 = open(path, "w+")
    acc = (tp+tn)/(tp+tn+fp+fn)
    pre_es = tp/(tp+fp)
    pre_nes = tn/(tn+fn)
    f1.write("Accuracy: "+str(acc)+"\n"+"precision_es: "+str(pre_es)+"\n"+"precision_nes: "+str(pre_nes))
    f1.close()  


def save_data_to_json(data, file_path):
    try:
        with open(file_path, 'w') as file:
            json.dump(data, file)
        print(f"Data successfully saved to {file_path}")
    except Exception as e:
        print(f"Error saving data to {file_path}: {e}")