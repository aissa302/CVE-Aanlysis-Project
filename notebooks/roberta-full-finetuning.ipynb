{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revo302/anaconda3/envs/ai/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1899: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/home/revo302/anaconda3/envs/ai/lib/python3.11/site-packages/transformers/modeling_utils.py:2759: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "import torch\n",
    "\n",
    "\n",
    "model_id = 'FacebookAI/roberta-base'\n",
    "your_token = \"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\" # Replace with your actual token\n",
    "# Load the tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', use_auth_token=your_token)\n",
    "\n",
    "# Load the RoBERTa model\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', use_auth_token=your_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"/home/revo302/repos/CVE-Aanlysis-Project/data/data/dataset.csv\")\n",
    "\n",
    "# Labels Encoding\n",
    "df['label'] = df.label.map({'esv':0, 'gpsv':1})\n",
    "\n",
    "\n",
    "# Assuming `texts` and `labels` are your dataset\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(df.description, df.label, test_size=0.2)\n",
    "\n",
    "train_texts = train_texts.reset_index(drop=True)\n",
    "val_texts = val_texts.reset_index(drop=True)\n",
    "train_labels = train_labels.reset_index(drop=True)\n",
    "val_labels = val_labels.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=512)\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['label'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "train_dataset = TextDataset(list(train_texts), train_labels, tokenizer=tokenizer)\n",
    "validation_dataset = TextDataset(list(val_texts), val_labels, tokenizer=tokenizer)\n",
    "#dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-28 10:42:04.880868: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0acb14e5d2431290e9fee36c87999d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26535 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revo302/anaconda3/envs/ai/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6763, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.0}\n",
      "{'loss': 0.688, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.0}\n",
      "{'loss': 0.6857, 'learning_rate': 3e-06, 'epoch': 0.0}\n",
      "{'loss': 0.6664, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.0}\n",
      "{'loss': 0.6489, 'learning_rate': 5e-06, 'epoch': 0.01}\n",
      "{'loss': 0.6228, 'learning_rate': 6e-06, 'epoch': 0.01}\n",
      "{'loss': 0.6329, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.01}\n",
      "{'loss': 0.4339, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.01}\n",
      "{'loss': 0.6112, 'learning_rate': 9e-06, 'epoch': 0.01}\n",
      "{'loss': 0.726, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 0.5699, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.01}\n",
      "{'loss': 0.5193, 'learning_rate': 1.2e-05, 'epoch': 0.01}\n",
      "{'loss': 0.3488, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.01}\n",
      "{'loss': 0.2808, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.02}\n",
      "{'loss': 0.2034, 'learning_rate': 1.5e-05, 'epoch': 0.02}\n",
      "{'loss': 0.0145, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.02}\n",
      "{'loss': 0.2481, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.02}\n",
      "{'loss': 0.1445, 'learning_rate': 1.8e-05, 'epoch': 0.02}\n",
      "{'loss': 0.1285, 'learning_rate': 1.9e-05, 'epoch': 0.02}\n",
      "{'loss': 0.1701, 'learning_rate': 2e-05, 'epoch': 0.02}\n",
      "{'loss': 0.1527, 'learning_rate': 2.1e-05, 'epoch': 0.02}\n",
      "{'loss': 0.1774, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.02}\n",
      "{'loss': 0.0113, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.03}\n",
      "{'loss': 0.3756, 'learning_rate': 2.4e-05, 'epoch': 0.03}\n",
      "{'loss': 0.4294, 'learning_rate': 2.5e-05, 'epoch': 0.03}\n",
      "{'loss': 0.1991, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.03}\n",
      "{'loss': 0.0059, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.03}\n",
      "{'loss': 0.0028, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.03}\n",
      "{'loss': 0.0031, 'learning_rate': 2.9e-05, 'epoch': 0.03}\n",
      "{'loss': 0.1761, 'learning_rate': 3e-05, 'epoch': 0.03}\n",
      "{'loss': 0.0661, 'learning_rate': 3.1e-05, 'epoch': 0.04}\n",
      "{'loss': 0.7539, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.04}\n",
      "{'loss': 0.3864, 'learning_rate': 3.3e-05, 'epoch': 0.04}\n",
      "{'loss': 0.4497, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.04}\n",
      "{'loss': 0.1691, 'learning_rate': 3.5e-05, 'epoch': 0.04}\n",
      "{'loss': 0.1298, 'learning_rate': 3.6e-05, 'epoch': 0.04}\n",
      "{'loss': 0.1252, 'learning_rate': 3.7e-05, 'epoch': 0.04}\n",
      "{'loss': 0.0019, 'learning_rate': 3.8e-05, 'epoch': 0.04}\n",
      "{'loss': 0.1607, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.04}\n",
      "{'loss': 0.2673, 'learning_rate': 4e-05, 'epoch': 0.05}\n",
      "{'loss': 0.0809, 'learning_rate': 4.1e-05, 'epoch': 0.05}\n",
      "{'loss': 0.0008, 'learning_rate': 4.2e-05, 'epoch': 0.05}\n",
      "{'loss': 0.0011, 'learning_rate': 4.3e-05, 'epoch': 0.05}\n",
      "{'loss': 0.0003, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.05}\n",
      "{'loss': 0.0623, 'learning_rate': 4.5e-05, 'epoch': 0.05}\n",
      "{'loss': 0.1938, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.05}\n",
      "{'loss': 0.1552, 'learning_rate': 4.7e-05, 'epoch': 0.05}\n",
      "{'loss': 0.1322, 'learning_rate': 4.8e-05, 'epoch': 0.05}\n",
      "{'loss': 0.0035, 'learning_rate': 4.9e-05, 'epoch': 0.06}\n",
      "{'loss': 0.1088, 'learning_rate': 5e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revo302/anaconda3/envs/ai/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4041, 'learning_rate': 4.998079508354139e-05, 'epoch': 0.06}\n",
      "{'loss': 0.4411, 'learning_rate': 4.996159016708278e-05, 'epoch': 0.06}\n",
      "{'loss': 0.4075, 'learning_rate': 4.9942385250624164e-05, 'epoch': 0.06}\n",
      "{'loss': 0.163, 'learning_rate': 4.9923180334165545e-05, 'epoch': 0.06}\n",
      "{'loss': 0.0046, 'learning_rate': 4.990397541770693e-05, 'epoch': 0.06}\n",
      "{'loss': 0.0005, 'learning_rate': 4.9884770501248326e-05, 'epoch': 0.06}\n",
      "{'loss': 0.0016, 'learning_rate': 4.986556558478971e-05, 'epoch': 0.06}\n",
      "{'loss': 0.0003, 'learning_rate': 4.9846360668331094e-05, 'epoch': 0.07}\n",
      "{'loss': 0.0021, 'learning_rate': 4.982715575187248e-05, 'epoch': 0.07}\n",
      "{'loss': 0.0002, 'learning_rate': 4.980795083541387e-05, 'epoch': 0.07}\n",
      "{'loss': 0.2132, 'learning_rate': 4.9788745918955256e-05, 'epoch': 0.07}\n",
      "{'loss': 0.3928, 'learning_rate': 4.976954100249664e-05, 'epoch': 0.07}\n",
      "{'loss': 0.2938, 'learning_rate': 4.975033608603803e-05, 'epoch': 0.07}\n",
      "{'loss': 0.1791, 'learning_rate': 4.973113116957941e-05, 'epoch': 0.07}\n",
      "{'loss': 0.1038, 'learning_rate': 4.97119262531208e-05, 'epoch': 0.07}\n",
      "{'loss': 0.3738, 'learning_rate': 4.969272133666219e-05, 'epoch': 0.07}\n",
      "{'loss': 0.0014, 'learning_rate': 4.9673516420203574e-05, 'epoch': 0.08}\n",
      "{'loss': 0.001, 'learning_rate': 4.965431150374496e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0062, 'learning_rate': 4.963510658728635e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0178, 'learning_rate': 4.9615901670827736e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0004, 'learning_rate': 4.959669675436912e-05, 'epoch': 0.08}\n",
      "{'loss': 0.2048, 'learning_rate': 4.9577491837910504e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0009, 'learning_rate': 4.95582869214519e-05, 'epoch': 0.08}\n",
      "{'loss': 0.001, 'learning_rate': 4.953908200499328e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0005, 'learning_rate': 4.9519877088534666e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0003, 'learning_rate': 4.950067217207605e-05, 'epoch': 0.09}\n",
      "{'loss': 0.3524, 'learning_rate': 4.948146725561744e-05, 'epoch': 0.09}\n",
      "{'loss': 0.3663, 'learning_rate': 4.946226233915883e-05, 'epoch': 0.09}\n",
      "{'loss': 0.0256, 'learning_rate': 4.9443057422700215e-05, 'epoch': 0.09}\n",
      "{'loss': 0.012, 'learning_rate': 4.94238525062416e-05, 'epoch': 0.09}\n",
      "{'loss': 0.0012, 'learning_rate': 4.940464758978299e-05, 'epoch': 0.09}\n",
      "{'loss': 0.0004, 'learning_rate': 4.938544267332437e-05, 'epoch': 0.09}\n",
      "{'loss': 0.1922, 'learning_rate': 4.936623775686576e-05, 'epoch': 0.09}\n",
      "{'loss': 0.0006, 'learning_rate': 4.9347032840407145e-05, 'epoch': 0.09}\n",
      "{'loss': 0.1689, 'learning_rate': 4.932782792394853e-05, 'epoch': 0.1}\n",
      "{'loss': 0.18, 'learning_rate': 4.930862300748992e-05, 'epoch': 0.1}\n",
      "{'loss': 0.0013, 'learning_rate': 4.928941809103131e-05, 'epoch': 0.1}\n",
      "{'loss': 0.1834, 'learning_rate': 4.9270213174572694e-05, 'epoch': 0.1}\n",
      "{'loss': 0.0007, 'learning_rate': 4.925100825811408e-05, 'epoch': 0.1}\n",
      "{'loss': 0.0082, 'learning_rate': 4.923180334165546e-05, 'epoch': 0.1}\n",
      "{'loss': 0.1937, 'learning_rate': 4.9212598425196856e-05, 'epoch': 0.1}\n",
      "{'loss': 0.001, 'learning_rate': 4.919339350873824e-05, 'epoch': 0.1}\n",
      "{'loss': 0.0462, 'learning_rate': 4.9174188592279624e-05, 'epoch': 0.11}\n",
      "{'loss': 0.0005, 'learning_rate': 4.915498367582101e-05, 'epoch': 0.11}\n",
      "{'loss': 0.1483, 'learning_rate': 4.91357787593624e-05, 'epoch': 0.11}\n",
      "{'loss': 0.1852, 'learning_rate': 4.9116573842903786e-05, 'epoch': 0.11}\n",
      "{'loss': 0.0042, 'learning_rate': 4.909736892644517e-05, 'epoch': 0.11}\n",
      "{'loss': 0.1705, 'learning_rate': 4.907816400998656e-05, 'epoch': 0.11}\n",
      "{'loss': 0.5342, 'learning_rate': 4.905895909352795e-05, 'epoch': 0.11}\n",
      "{'loss': 0.6547, 'learning_rate': 4.903975417706933e-05, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revo302/anaconda3/envs/ai/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0431, 'learning_rate': 4.902054926061072e-05, 'epoch': 0.11}\n",
      "{'loss': 0.3085, 'learning_rate': 4.9001344344152104e-05, 'epoch': 0.12}\n",
      "{'loss': 0.33, 'learning_rate': 4.898213942769349e-05, 'epoch': 0.12}\n",
      "{'loss': 0.4098, 'learning_rate': 4.896293451123488e-05, 'epoch': 0.12}\n",
      "{'loss': 0.1565, 'learning_rate': 4.8943729594776266e-05, 'epoch': 0.12}\n",
      "{'loss': 0.0245, 'learning_rate': 4.892452467831765e-05, 'epoch': 0.12}\n",
      "{'loss': 0.2542, 'learning_rate': 4.8905319761859034e-05, 'epoch': 0.12}\n",
      "{'loss': 0.0008, 'learning_rate': 4.888611484540043e-05, 'epoch': 0.12}\n",
      "{'loss': 0.1503, 'learning_rate': 4.8866909928941815e-05, 'epoch': 0.12}\n",
      "{'loss': 0.187, 'learning_rate': 4.8847705012483196e-05, 'epoch': 0.12}\n",
      "{'loss': 0.1406, 'learning_rate': 4.882850009602458e-05, 'epoch': 0.13}\n",
      "{'loss': 0.2316, 'learning_rate': 4.880929517956597e-05, 'epoch': 0.13}\n",
      "{'loss': 0.1088, 'learning_rate': 4.879009026310736e-05, 'epoch': 0.13}\n",
      "{'loss': 0.0103, 'learning_rate': 4.8770885346648745e-05, 'epoch': 0.13}\n",
      "{'loss': 0.0003, 'learning_rate': 4.875168043019013e-05, 'epoch': 0.13}\n",
      "{'loss': 0.2163, 'learning_rate': 4.873247551373152e-05, 'epoch': 0.13}\n",
      "{'loss': 0.0011, 'learning_rate': 4.87132705972729e-05, 'epoch': 0.13}\n",
      "{'loss': 0.179, 'learning_rate': 4.869406568081429e-05, 'epoch': 0.13}\n",
      "{'loss': 0.0758, 'learning_rate': 4.867486076435568e-05, 'epoch': 0.13}\n",
      "{'loss': 0.1408, 'learning_rate': 4.865565584789706e-05, 'epoch': 0.14}\n",
      "{'loss': 0.0088, 'learning_rate': 4.863645093143845e-05, 'epoch': 0.14}\n",
      "{'loss': 0.0006, 'learning_rate': 4.861724601497984e-05, 'epoch': 0.14}\n",
      "{'loss': 0.0006, 'learning_rate': 4.8598041098521224e-05, 'epoch': 0.14}\n",
      "{'loss': 0.0004, 'learning_rate': 4.857883618206261e-05, 'epoch': 0.14}\n",
      "{'loss': 0.2896, 'learning_rate': 4.855963126560399e-05, 'epoch': 0.14}\n",
      "{'loss': 0.0005, 'learning_rate': 4.8540426349145387e-05, 'epoch': 0.14}\n",
      "{'loss': 0.1474, 'learning_rate': 4.852122143268677e-05, 'epoch': 0.14}\n",
      "{'loss': 0.1769, 'learning_rate': 4.8502016516228154e-05, 'epoch': 0.14}\n",
      "{'loss': 0.3008, 'learning_rate': 4.848281159976955e-05, 'epoch': 0.15}\n",
      "{'loss': 0.0017, 'learning_rate': 4.846360668331093e-05, 'epoch': 0.15}\n",
      "{'loss': 0.1511, 'learning_rate': 4.8444401766852316e-05, 'epoch': 0.15}\n",
      "{'loss': 0.004, 'learning_rate': 4.84251968503937e-05, 'epoch': 0.15}\n",
      "{'loss': 0.159, 'learning_rate': 4.840599193393509e-05, 'epoch': 0.15}\n",
      "{'loss': 0.1962, 'learning_rate': 4.838678701747648e-05, 'epoch': 0.15}\n",
      "{'loss': 0.1475, 'learning_rate': 4.836758210101786e-05, 'epoch': 0.15}\n",
      "{'loss': 0.1882, 'learning_rate': 4.834837718455925e-05, 'epoch': 0.15}\n",
      "{'loss': 0.0013, 'learning_rate': 4.8329172268100634e-05, 'epoch': 0.15}\n",
      "{'loss': 0.0008, 'learning_rate': 4.830996735164202e-05, 'epoch': 0.16}\n",
      "{'loss': 0.0004, 'learning_rate': 4.8290762435183415e-05, 'epoch': 0.16}\n",
      "{'loss': 0.1607, 'learning_rate': 4.8271557518724796e-05, 'epoch': 0.16}\n",
      "{'loss': 0.0022, 'learning_rate': 4.825235260226618e-05, 'epoch': 0.16}\n",
      "{'loss': 0.2123, 'learning_rate': 4.8233147685807564e-05, 'epoch': 0.16}\n",
      "{'loss': 0.1717, 'learning_rate': 4.821394276934896e-05, 'epoch': 0.16}\n",
      "{'loss': 0.142, 'learning_rate': 4.8194737852890345e-05, 'epoch': 0.16}\n",
      "{'loss': 0.2354, 'learning_rate': 4.8175532936431726e-05, 'epoch': 0.16}\n",
      "{'loss': 0.0027, 'learning_rate': 4.815632801997312e-05, 'epoch': 0.17}\n",
      "{'loss': 0.0029, 'learning_rate': 4.81371231035145e-05, 'epoch': 0.17}\n",
      "{'loss': 0.0004, 'learning_rate': 4.811791818705589e-05, 'epoch': 0.17}\n",
      "{'loss': 0.0012, 'learning_rate': 4.8098713270597275e-05, 'epoch': 0.17}\n",
      "{'loss': 0.0261, 'learning_rate': 4.807950835413866e-05, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revo302/anaconda3/envs/ai/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1209, 'learning_rate': 4.806030343768005e-05, 'epoch': 0.17}\n",
      "{'loss': 0.0002, 'learning_rate': 4.804109852122143e-05, 'epoch': 0.17}\n",
      "{'loss': 0.0002, 'learning_rate': 4.8021893604762825e-05, 'epoch': 0.17}\n",
      "{'loss': 0.0002, 'learning_rate': 4.800268868830421e-05, 'epoch': 0.17}\n",
      "{'loss': 0.079, 'learning_rate': 4.798348377184559e-05, 'epoch': 0.18}\n",
      "{'loss': 0.0001, 'learning_rate': 4.796427885538698e-05, 'epoch': 0.18}\n",
      "{'loss': 0.2094, 'learning_rate': 4.794507393892837e-05, 'epoch': 0.18}\n",
      "{'loss': 0.0006, 'learning_rate': 4.7925869022469754e-05, 'epoch': 0.18}\n",
      "{'loss': 0.0005, 'learning_rate': 4.790666410601114e-05, 'epoch': 0.18}\n",
      "{'loss': 0.1679, 'learning_rate': 4.788745918955253e-05, 'epoch': 0.18}\n",
      "{'loss': 0.0005, 'learning_rate': 4.7868254273093917e-05, 'epoch': 0.18}\n",
      "{'loss': 0.0005, 'learning_rate': 4.78490493566353e-05, 'epoch': 0.18}\n",
      "{'loss': 0.0004, 'learning_rate': 4.7829844440176684e-05, 'epoch': 0.18}\n",
      "{'loss': 0.238, 'learning_rate': 4.781063952371808e-05, 'epoch': 0.19}\n",
      "{'loss': 0.1831, 'learning_rate': 4.779143460725946e-05, 'epoch': 0.19}\n",
      "{'loss': 0.0009, 'learning_rate': 4.7772229690800846e-05, 'epoch': 0.19}\n",
      "{'loss': 0.0005, 'learning_rate': 4.7753024774342234e-05, 'epoch': 0.19}\n",
      "{'loss': 0.0003, 'learning_rate': 4.773381985788362e-05, 'epoch': 0.19}\n",
      "{'loss': 0.0002, 'learning_rate': 4.771461494142501e-05, 'epoch': 0.19}\n",
      "{'loss': 0.0003, 'learning_rate': 4.769541002496639e-05, 'epoch': 0.19}\n",
      "{'loss': 0.0009, 'learning_rate': 4.767620510850778e-05, 'epoch': 0.19}\n",
      "{'loss': 0.1743, 'learning_rate': 4.7657000192049164e-05, 'epoch': 0.19}\n",
      "{'loss': 0.0006, 'learning_rate': 4.763779527559055e-05, 'epoch': 0.2}\n",
      "{'loss': 0.0008, 'learning_rate': 4.7618590359131945e-05, 'epoch': 0.2}\n",
      "{'loss': 0.1145, 'learning_rate': 4.7599385442673326e-05, 'epoch': 0.2}\n",
      "{'loss': 0.0002, 'learning_rate': 4.758018052621471e-05, 'epoch': 0.2}\n",
      "{'loss': 0.2672, 'learning_rate': 4.75609756097561e-05, 'epoch': 0.2}\n",
      "{'loss': 0.09, 'learning_rate': 4.754177069329749e-05, 'epoch': 0.2}\n",
      "{'loss': 0.0002, 'learning_rate': 4.7522565776838875e-05, 'epoch': 0.2}\n",
      "{'loss': 0.2166, 'learning_rate': 4.7503360860380256e-05, 'epoch': 0.2}\n",
      "{'loss': 0.0008, 'learning_rate': 4.748415594392165e-05, 'epoch': 0.2}\n",
      "{'loss': 0.2467, 'learning_rate': 4.746495102746303e-05, 'epoch': 0.21}\n",
      "{'loss': 0.1273, 'learning_rate': 4.744574611100442e-05, 'epoch': 0.21}\n",
      "{'loss': 0.0005, 'learning_rate': 4.7426541194545805e-05, 'epoch': 0.21}\n",
      "{'loss': 0.0523, 'learning_rate': 4.740733627808719e-05, 'epoch': 0.21}\n",
      "{'loss': 0.193, 'learning_rate': 4.738813136162858e-05, 'epoch': 0.21}\n",
      "{'loss': 0.4248, 'learning_rate': 4.736892644516997e-05, 'epoch': 0.21}\n",
      "{'loss': 0.0489, 'learning_rate': 4.7349721528711355e-05, 'epoch': 0.21}\n",
      "{'loss': 0.4412, 'learning_rate': 4.733051661225274e-05, 'epoch': 0.21}\n",
      "{'loss': 0.0179, 'learning_rate': 4.731131169579412e-05, 'epoch': 0.21}\n",
      "{'loss': 0.0009, 'learning_rate': 4.729210677933551e-05, 'epoch': 0.22}\n",
      "{'loss': 0.0106, 'learning_rate': 4.72729018628769e-05, 'epoch': 0.22}\n",
      "{'loss': 0.3364, 'learning_rate': 4.7253696946418284e-05, 'epoch': 0.22}\n",
      "{'loss': 0.0036, 'learning_rate': 4.723449202995967e-05, 'epoch': 0.22}\n",
      "{'loss': 0.001, 'learning_rate': 4.721528711350106e-05, 'epoch': 0.22}\n",
      "{'loss': 0.0006, 'learning_rate': 4.7196082197042447e-05, 'epoch': 0.22}\n",
      "{'loss': 0.0005, 'learning_rate': 4.7176877280583834e-05, 'epoch': 0.22}\n",
      "{'loss': 0.0004, 'learning_rate': 4.7157672364125214e-05, 'epoch': 0.22}\n",
      "{'loss': 0.0005, 'learning_rate': 4.713846744766661e-05, 'epoch': 0.22}\n",
      "{'loss': 0.2192, 'learning_rate': 4.711926253120799e-05, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revo302/anaconda3/envs/ai/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0008, 'learning_rate': 4.7100057614749376e-05, 'epoch': 0.23}\n",
      "{'loss': 0.2173, 'learning_rate': 4.7080852698290764e-05, 'epoch': 0.23}\n",
      "{'loss': 0.1937, 'learning_rate': 4.706164778183215e-05, 'epoch': 0.23}\n",
      "{'loss': 0.0021, 'learning_rate': 4.704244286537354e-05, 'epoch': 0.23}\n",
      "{'loss': 0.1616, 'learning_rate': 4.702323794891492e-05, 'epoch': 0.23}\n",
      "{'loss': 0.1659, 'learning_rate': 4.700403303245631e-05, 'epoch': 0.23}\n",
      "{'loss': 0.0013, 'learning_rate': 4.69848281159977e-05, 'epoch': 0.23}\n",
      "{'loss': 0.178, 'learning_rate': 4.696562319953908e-05, 'epoch': 0.24}\n",
      "{'loss': 0.0025, 'learning_rate': 4.6946418283080475e-05, 'epoch': 0.24}\n",
      "{'loss': 0.0015, 'learning_rate': 4.6927213366621856e-05, 'epoch': 0.24}\n",
      "{'loss': 0.0008, 'learning_rate': 4.690800845016324e-05, 'epoch': 0.24}\n",
      "{'loss': 0.0006, 'learning_rate': 4.688880353370463e-05, 'epoch': 0.24}\n",
      "{'loss': 0.0005, 'learning_rate': 4.686959861724602e-05, 'epoch': 0.24}\n",
      "{'loss': 0.1682, 'learning_rate': 4.6850393700787405e-05, 'epoch': 0.24}\n",
      "{'loss': 0.2095, 'learning_rate': 4.6831188784328786e-05, 'epoch': 0.24}\n",
      "{'loss': 0.2989, 'learning_rate': 4.681198386787018e-05, 'epoch': 0.24}\n",
      "{'loss': 0.3548, 'learning_rate': 4.679277895141157e-05, 'epoch': 0.25}\n",
      "{'loss': 0.1438, 'learning_rate': 4.677357403495295e-05, 'epoch': 0.25}\n",
      "{'loss': 0.0028, 'learning_rate': 4.6754369118494335e-05, 'epoch': 0.25}\n",
      "{'loss': 0.0018, 'learning_rate': 4.673516420203572e-05, 'epoch': 0.25}\n",
      "{'loss': 0.1571, 'learning_rate': 4.671595928557711e-05, 'epoch': 0.25}\n",
      "{'loss': 0.3457, 'learning_rate': 4.66967543691185e-05, 'epoch': 0.25}\n",
      "{'loss': 0.2965, 'learning_rate': 4.6677549452659885e-05, 'epoch': 0.25}\n",
      "{'loss': 0.0046, 'learning_rate': 4.665834453620127e-05, 'epoch': 0.25}\n",
      "{'loss': 0.1618, 'learning_rate': 4.663913961974265e-05, 'epoch': 0.25}\n",
      "{'loss': 0.2799, 'learning_rate': 4.661993470328404e-05, 'epoch': 0.26}\n",
      "{'loss': 0.0025, 'learning_rate': 4.6600729786825434e-05, 'epoch': 0.26}\n",
      "{'loss': 0.0115, 'learning_rate': 4.6581524870366815e-05, 'epoch': 0.26}\n",
      "{'loss': 0.0009, 'learning_rate': 4.65623199539082e-05, 'epoch': 0.26}\n",
      "{'loss': 0.1911, 'learning_rate': 4.654311503744959e-05, 'epoch': 0.26}\n",
      "{'loss': 0.1847, 'learning_rate': 4.6523910120990977e-05, 'epoch': 0.26}\n",
      "{'loss': 0.0012, 'learning_rate': 4.6504705204532364e-05, 'epoch': 0.26}\n",
      "{'loss': 0.0011, 'learning_rate': 4.6485500288073744e-05, 'epoch': 0.26}\n",
      "{'loss': 0.1765, 'learning_rate': 4.646629537161514e-05, 'epoch': 0.26}\n",
      "{'loss': 0.1066, 'learning_rate': 4.644709045515652e-05, 'epoch': 0.27}\n",
      "{'loss': 0.1744, 'learning_rate': 4.6427885538697906e-05, 'epoch': 0.27}\n",
      "{'loss': 0.0012, 'learning_rate': 4.64086806222393e-05, 'epoch': 0.27}\n",
      "{'loss': 0.0016, 'learning_rate': 4.638947570578068e-05, 'epoch': 0.27}\n",
      "{'loss': 0.2356, 'learning_rate': 4.637027078932207e-05, 'epoch': 0.27}\n",
      "{'loss': 0.019, 'learning_rate': 4.6351065872863456e-05, 'epoch': 0.27}\n",
      "{'loss': 0.0009, 'learning_rate': 4.633186095640484e-05, 'epoch': 0.27}\n",
      "{'loss': 0.1809, 'learning_rate': 4.631265603994623e-05, 'epoch': 0.27}\n",
      "{'loss': 0.001, 'learning_rate': 4.629345112348761e-05, 'epoch': 0.27}\n",
      "{'loss': 1.854, 'learning_rate': 4.6274246207029005e-05, 'epoch': 0.28}\n",
      "{'loss': 0.0344, 'learning_rate': 4.6255041290570386e-05, 'epoch': 0.28}\n",
      "{'loss': 0.0043, 'learning_rate': 4.623583637411177e-05, 'epoch': 0.28}\n",
      "{'loss': 0.0012, 'learning_rate': 4.621663145765316e-05, 'epoch': 0.28}\n",
      "{'loss': 0.1046, 'learning_rate': 4.619742654119455e-05, 'epoch': 0.28}\n",
      "{'loss': 0.1962, 'learning_rate': 4.6178221624735935e-05, 'epoch': 0.28}\n",
      "{'loss': 0.1625, 'learning_rate': 4.615901670827732e-05, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revo302/anaconda3/envs/ai/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.202, 'learning_rate': 4.613981179181871e-05, 'epoch': 0.28}\n",
      "{'loss': 0.0004, 'learning_rate': 4.61206068753601e-05, 'epoch': 0.28}\n",
      "{'loss': 0.0003, 'learning_rate': 4.610140195890148e-05, 'epoch': 0.29}\n",
      "{'loss': 0.1952, 'learning_rate': 4.6082197042442865e-05, 'epoch': 0.29}\n",
      "{'loss': 0.4951, 'learning_rate': 4.606299212598425e-05, 'epoch': 0.29}\n",
      "{'loss': 0.0035, 'learning_rate': 4.604378720952564e-05, 'epoch': 0.29}\n",
      "{'loss': 0.1866, 'learning_rate': 4.602458229306703e-05, 'epoch': 0.29}\n",
      "{'loss': 0.1579, 'learning_rate': 4.6005377376608415e-05, 'epoch': 0.29}\n",
      "{'loss': 0.2489, 'learning_rate': 4.59861724601498e-05, 'epoch': 0.29}\n",
      "{'loss': 0.5826, 'learning_rate': 4.596696754369119e-05, 'epoch': 0.29}\n",
      "{'loss': 0.023, 'learning_rate': 4.594776262723257e-05, 'epoch': 0.3}\n",
      "{'loss': 0.0939, 'learning_rate': 4.5928557710773964e-05, 'epoch': 0.3}\n",
      "{'loss': 0.1848, 'learning_rate': 4.5909352794315345e-05, 'epoch': 0.3}\n",
      "{'loss': 0.0028, 'learning_rate': 4.589014787785673e-05, 'epoch': 0.3}\n",
      "{'loss': 0.0012, 'learning_rate': 4.587094296139812e-05, 'epoch': 0.3}\n",
      "{'loss': 0.1891, 'learning_rate': 4.5851738044939507e-05, 'epoch': 0.3}\n",
      "{'loss': 0.1551, 'learning_rate': 4.5832533128480894e-05, 'epoch': 0.3}\n",
      "{'loss': 0.1756, 'learning_rate': 4.5813328212022274e-05, 'epoch': 0.3}\n",
      "{'loss': 0.0023, 'learning_rate': 4.579412329556367e-05, 'epoch': 0.3}\n",
      "{'loss': 0.3061, 'learning_rate': 4.5774918379105056e-05, 'epoch': 0.31}\n",
      "{'loss': 0.004, 'learning_rate': 4.5755713462646437e-05, 'epoch': 0.31}\n",
      "{'loss': 0.0017, 'learning_rate': 4.573650854618783e-05, 'epoch': 0.31}\n",
      "{'loss': 0.0009, 'learning_rate': 4.571730362972921e-05, 'epoch': 0.31}\n",
      "{'loss': 0.1438, 'learning_rate': 4.56980987132706e-05, 'epoch': 0.31}\n",
      "{'loss': 0.2789, 'learning_rate': 4.5678893796811986e-05, 'epoch': 0.31}\n",
      "{'loss': 0.0387, 'learning_rate': 4.565968888035337e-05, 'epoch': 0.31}\n",
      "{'loss': 0.1519, 'learning_rate': 4.564048396389476e-05, 'epoch': 0.31}\n",
      "{'loss': 0.1802, 'learning_rate': 4.562127904743614e-05, 'epoch': 0.31}\n",
      "{'loss': 0.0009, 'learning_rate': 4.5602074130977535e-05, 'epoch': 0.32}\n",
      "{'loss': 0.1627, 'learning_rate': 4.558286921451892e-05, 'epoch': 0.32}\n",
      "{'loss': 0.0008, 'learning_rate': 4.55636642980603e-05, 'epoch': 0.32}\n",
      "{'loss': 0.0973, 'learning_rate': 4.554445938160169e-05, 'epoch': 0.32}\n",
      "{'loss': 0.1875, 'learning_rate': 4.552525446514308e-05, 'epoch': 0.32}\n",
      "{'loss': 0.0012, 'learning_rate': 4.5506049548684465e-05, 'epoch': 0.32}\n",
      "{'loss': 0.0028, 'learning_rate': 4.548684463222585e-05, 'epoch': 0.32}\n",
      "{'loss': 0.1541, 'learning_rate': 4.546763971576724e-05, 'epoch': 0.32}\n",
      "{'loss': 0.1373, 'learning_rate': 4.544843479930863e-05, 'epoch': 0.32}\n",
      "{'loss': 0.0006, 'learning_rate': 4.542922988285001e-05, 'epoch': 0.33}\n",
      "{'loss': 0.0014, 'learning_rate': 4.5410024966391395e-05, 'epoch': 0.33}\n",
      "{'loss': 0.0006, 'learning_rate': 4.539082004993279e-05, 'epoch': 0.33}\n",
      "{'loss': 0.1212, 'learning_rate': 4.537161513347417e-05, 'epoch': 0.33}\n",
      "{'loss': 0.2659, 'learning_rate': 4.535241021701556e-05, 'epoch': 0.33}\n",
      "{'loss': 0.0164, 'learning_rate': 4.5333205300556945e-05, 'epoch': 0.33}\n",
      "{'loss': 0.3408, 'learning_rate': 4.531400038409833e-05, 'epoch': 0.33}\n",
      "{'loss': 0.116, 'learning_rate': 4.529479546763972e-05, 'epoch': 0.33}\n",
      "{'loss': 0.2512, 'learning_rate': 4.52755905511811e-05, 'epoch': 0.33}\n",
      "{'loss': 0.1224, 'learning_rate': 4.5256385634722494e-05, 'epoch': 0.34}\n",
      "{'loss': 0.003, 'learning_rate': 4.5237180718263875e-05, 'epoch': 0.34}\n",
      "{'loss': 0.0039, 'learning_rate': 4.521797580180526e-05, 'epoch': 0.34}\n",
      "{'loss': 0.191, 'learning_rate': 4.5198770885346656e-05, 'epoch': 0.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revo302/anaconda3/envs/ai/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.168, 'learning_rate': 4.5179565968888037e-05, 'epoch': 0.34}\n",
      "{'loss': 0.1454, 'learning_rate': 4.5160361052429424e-05, 'epoch': 0.34}\n",
      "{'loss': 0.1351, 'learning_rate': 4.514115613597081e-05, 'epoch': 0.34}\n",
      "{'loss': 0.2592, 'learning_rate': 4.51219512195122e-05, 'epoch': 0.34}\n",
      "{'loss': 0.0083, 'learning_rate': 4.5102746303053586e-05, 'epoch': 0.34}\n",
      "{'loss': 0.0233, 'learning_rate': 4.5083541386594967e-05, 'epoch': 0.35}\n",
      "{'loss': 0.0373, 'learning_rate': 4.506433647013636e-05, 'epoch': 0.35}\n",
      "{'loss': 0.0013, 'learning_rate': 4.504513155367774e-05, 'epoch': 0.35}\n",
      "{'loss': 0.0009, 'learning_rate': 4.502592663721913e-05, 'epoch': 0.35}\n",
      "{'loss': 0.0007, 'learning_rate': 4.5006721720760516e-05, 'epoch': 0.35}\n",
      "{'loss': 0.0005, 'learning_rate': 4.49875168043019e-05, 'epoch': 0.35}\n",
      "{'loss': 0.053, 'learning_rate': 4.496831188784329e-05, 'epoch': 0.35}\n",
      "{'loss': 0.1806, 'learning_rate': 4.494910697138468e-05, 'epoch': 0.35}\n",
      "{'loss': 0.0007, 'learning_rate': 4.4929902054926065e-05, 'epoch': 0.36}\n",
      "{'loss': 0.1572, 'learning_rate': 4.491069713846745e-05, 'epoch': 0.36}\n",
      "{'loss': 0.0011, 'learning_rate': 4.489149222200883e-05, 'epoch': 0.36}\n",
      "{'loss': 0.0626, 'learning_rate': 4.487228730555023e-05, 'epoch': 0.36}\n",
      "{'loss': 0.1417, 'learning_rate': 4.485308238909161e-05, 'epoch': 0.36}\n",
      "{'loss': 0.0023, 'learning_rate': 4.4833877472632995e-05, 'epoch': 0.36}\n",
      "{'loss': 0.2088, 'learning_rate': 4.481467255617438e-05, 'epoch': 0.36}\n",
      "{'loss': 0.1374, 'learning_rate': 4.479546763971577e-05, 'epoch': 0.36}\n",
      "{'loss': 0.1505, 'learning_rate': 4.477626272325716e-05, 'epoch': 0.36}\n",
      "{'loss': 0.1191, 'learning_rate': 4.4757057806798545e-05, 'epoch': 0.37}\n",
      "{'loss': 0.1126, 'learning_rate': 4.473785289033993e-05, 'epoch': 0.37}\n",
      "{'loss': 0.0041, 'learning_rate': 4.471864797388132e-05, 'epoch': 0.37}\n",
      "{'loss': 0.0031, 'learning_rate': 4.46994430574227e-05, 'epoch': 0.37}\n",
      "{'loss': 0.2007, 'learning_rate': 4.468023814096409e-05, 'epoch': 0.37}\n",
      "{'loss': 0.1375, 'learning_rate': 4.4661033224505475e-05, 'epoch': 0.37}\n",
      "{'loss': 0.3068, 'learning_rate': 4.464182830804686e-05, 'epoch': 0.37}\n",
      "{'loss': 0.1218, 'learning_rate': 4.462262339158825e-05, 'epoch': 0.37}\n",
      "{'loss': 0.1432, 'learning_rate': 4.460341847512964e-05, 'epoch': 0.37}\n",
      "{'loss': 0.0059, 'learning_rate': 4.4584213558671024e-05, 'epoch': 0.38}\n",
      "{'loss': 0.1585, 'learning_rate': 4.456500864221241e-05, 'epoch': 0.38}\n",
      "{'loss': 0.0994, 'learning_rate': 4.454580372575379e-05, 'epoch': 0.38}\n",
      "{'loss': 0.0148, 'learning_rate': 4.4526598809295186e-05, 'epoch': 0.38}\n",
      "{'loss': 0.1289, 'learning_rate': 4.4507393892836567e-05, 'epoch': 0.38}\n",
      "{'loss': 0.2615, 'learning_rate': 4.4488188976377954e-05, 'epoch': 0.38}\n",
      "{'loss': 0.002, 'learning_rate': 4.446898405991934e-05, 'epoch': 0.38}\n",
      "{'loss': 0.0022, 'learning_rate': 4.444977914346073e-05, 'epoch': 0.38}\n",
      "{'loss': 0.0014, 'learning_rate': 4.4430574227002116e-05, 'epoch': 0.38}\n",
      "{'loss': 0.0017, 'learning_rate': 4.4411369310543497e-05, 'epoch': 0.39}\n",
      "{'loss': 0.0008, 'learning_rate': 4.439216439408489e-05, 'epoch': 0.39}\n",
      "{'loss': 0.1569, 'learning_rate': 4.437295947762628e-05, 'epoch': 0.39}\n",
      "{'loss': 0.0091, 'learning_rate': 4.435375456116766e-05, 'epoch': 0.39}\n",
      "{'loss': 0.1954, 'learning_rate': 4.433454964470905e-05, 'epoch': 0.39}\n",
      "{'loss': 0.0012, 'learning_rate': 4.431534472825043e-05, 'epoch': 0.39}\n",
      "{'loss': 0.0014, 'learning_rate': 4.429613981179182e-05, 'epoch': 0.39}\n",
      "{'loss': 0.1854, 'learning_rate': 4.427693489533321e-05, 'epoch': 0.39}\n",
      "{'loss': 0.0102, 'learning_rate': 4.4257729978874595e-05, 'epoch': 0.39}\n",
      "{'loss': 0.0596, 'learning_rate': 4.423852506241598e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revo302/anaconda3/envs/ai/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2041, 'learning_rate': 4.421932014595736e-05, 'epoch': 0.4}\n",
      "{'loss': 0.1643, 'learning_rate': 4.420011522949876e-05, 'epoch': 0.4}\n",
      "{'loss': 0.0017, 'learning_rate': 4.4180910313040145e-05, 'epoch': 0.4}\n",
      "{'loss': 0.0013, 'learning_rate': 4.4161705396581525e-05, 'epoch': 0.4}\n",
      "{'loss': 0.458, 'learning_rate': 4.414250048012291e-05, 'epoch': 0.4}\n",
      "{'loss': 0.0054, 'learning_rate': 4.41232955636643e-05, 'epoch': 0.4}\n",
      "{'loss': 0.0036, 'learning_rate': 4.410409064720569e-05, 'epoch': 0.4}\n",
      "{'loss': 0.0027, 'learning_rate': 4.4084885730747075e-05, 'epoch': 0.4}\n",
      "{'loss': 0.0016, 'learning_rate': 4.406568081428846e-05, 'epoch': 0.41}\n",
      "{'loss': 0.0012, 'learning_rate': 4.404647589782985e-05, 'epoch': 0.41}\n",
      "{'loss': 0.001, 'learning_rate': 4.402727098137123e-05, 'epoch': 0.41}\n",
      "{'loss': 0.0009, 'learning_rate': 4.400806606491262e-05, 'epoch': 0.41}\n",
      "{'loss': 0.2038, 'learning_rate': 4.398886114845401e-05, 'epoch': 0.41}\n",
      "{'loss': 0.0006, 'learning_rate': 4.396965623199539e-05, 'epoch': 0.41}\n",
      "{'loss': 0.0004, 'learning_rate': 4.395045131553678e-05, 'epoch': 0.41}\n",
      "{'loss': 0.0622, 'learning_rate': 4.393124639907817e-05, 'epoch': 0.41}\n",
      "{'loss': 0.0004, 'learning_rate': 4.3912041482619554e-05, 'epoch': 0.41}\n",
      "{'loss': 0.0003, 'learning_rate': 4.389283656616094e-05, 'epoch': 0.42}\n",
      "{'loss': 0.0004, 'learning_rate': 4.387363164970232e-05, 'epoch': 0.42}\n",
      "{'loss': 0.2157, 'learning_rate': 4.3854426733243716e-05, 'epoch': 0.42}\n",
      "{'loss': 0.0004, 'learning_rate': 4.3835221816785097e-05, 'epoch': 0.42}\n",
      "{'loss': 0.292, 'learning_rate': 4.3816016900326484e-05, 'epoch': 0.42}\n",
      "{'loss': 0.2234, 'learning_rate': 4.379681198386788e-05, 'epoch': 0.42}\n",
      "{'loss': 0.3654, 'learning_rate': 4.377760706740926e-05, 'epoch': 0.42}\n",
      "{'loss': 0.1497, 'learning_rate': 4.3758402150950646e-05, 'epoch': 0.42}\n",
      "{'loss': 0.1531, 'learning_rate': 4.3739197234492027e-05, 'epoch': 0.43}\n",
      "{'loss': 0.004, 'learning_rate': 4.371999231803342e-05, 'epoch': 0.43}\n",
      "{'loss': 0.0065, 'learning_rate': 4.370078740157481e-05, 'epoch': 0.43}\n",
      "{'loss': 0.0015, 'learning_rate': 4.368158248511619e-05, 'epoch': 0.43}\n",
      "{'loss': 0.1332, 'learning_rate': 4.366237756865758e-05, 'epoch': 0.43}\n",
      "{'loss': 0.1794, 'learning_rate': 4.364317265219896e-05, 'epoch': 0.43}\n",
      "{'loss': 0.0012, 'learning_rate': 4.362396773574035e-05, 'epoch': 0.43}\n",
      "{'loss': 0.1717, 'learning_rate': 4.360476281928174e-05, 'epoch': 0.43}\n",
      "{'loss': 0.0018, 'learning_rate': 4.3585557902823125e-05, 'epoch': 0.43}\n",
      "{'loss': 0.0015, 'learning_rate': 4.356635298636451e-05, 'epoch': 0.44}\n",
      "{'loss': 0.0011, 'learning_rate': 4.354714806990589e-05, 'epoch': 0.44}\n",
      "{'loss': 0.0182, 'learning_rate': 4.352794315344729e-05, 'epoch': 0.44}\n",
      "{'loss': 0.0008, 'learning_rate': 4.3508738236988675e-05, 'epoch': 0.44}\n",
      "{'loss': 0.0702, 'learning_rate': 4.3489533320530055e-05, 'epoch': 0.44}\n",
      "{'loss': 0.0007, 'learning_rate': 4.347032840407144e-05, 'epoch': 0.44}\n",
      "{'loss': 0.0007, 'learning_rate': 4.345112348761283e-05, 'epoch': 0.44}\n",
      "{'loss': 0.0006, 'learning_rate': 4.343191857115422e-05, 'epoch': 0.44}\n",
      "{'loss': 0.1849, 'learning_rate': 4.3412713654695605e-05, 'epoch': 0.44}\n",
      "{'loss': 0.1904, 'learning_rate': 4.339350873823699e-05, 'epoch': 0.45}\n",
      "{'loss': 0.001, 'learning_rate': 4.337430382177838e-05, 'epoch': 0.45}\n",
      "{'loss': 0.001, 'learning_rate': 4.335509890531976e-05, 'epoch': 0.45}\n",
      "{'loss': 0.0323, 'learning_rate': 4.333589398886115e-05, 'epoch': 0.45}\n",
      "{'loss': 0.0008, 'learning_rate': 4.331668907240254e-05, 'epoch': 0.45}\n",
      "{'loss': 0.0008, 'learning_rate': 4.329748415594392e-05, 'epoch': 0.45}\n",
      "{'loss': 0.0007, 'learning_rate': 4.327827923948531e-05, 'epoch': 0.45}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:424] . unexpected pos 470625984 vs 470625872",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.11/site-packages/torch/serialization.py:619\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 619\u001b[0m     \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.11/site-packages/torch/serialization.py:853\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    852\u001b[0m num_bytes \u001b[38;5;241m=\u001b[39m storage\u001b[38;5;241m.\u001b[39mnbytes()\n\u001b[0;32m--> 853\u001b[0m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:588] . PytorchStreamWriter failed writing file data/2: file write failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 21\u001b[0m\n\u001b[1;32m      3\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      4\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/revo302/repos/CVE-Aanlysis-Project/results\u001b[39m\u001b[38;5;124m'\u001b[39m,          \u001b[38;5;66;03m# output directory\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,              \u001b[38;5;66;03m# total number of training epochs\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     logging_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     14\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     15\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     16\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m     17\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset, \u001b[38;5;66;03m# defined previously\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mvalidation_dataset, \u001b[38;5;66;03m# define your validation dataset\u001b[39;00m\n\u001b[1;32m     19\u001b[0m )\n\u001b[0;32m---> 21\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.11/site-packages/transformers/trainer.py:1537\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.11/site-packages/transformers/trainer.py:1914\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1911\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   1912\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 1914\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1916\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.11/site-packages/transformers/trainer.py:2279\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2276\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mstep(metrics[metric_to_check])\n\u001b[1;32m   2278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 2279\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2280\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_save(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.11/site-packages/transformers/trainer.py:2359\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   2355\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_model(staging_output_dir, _internal_call\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   2357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_only_model:\n\u001b[1;32m   2358\u001b[0m     \u001b[38;5;66;03m# Save optimizer and scheduler\u001b[39;00m\n\u001b[0;32m-> 2359\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_optimizer_and_scheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstaging_output_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2360\u001b[0m     \u001b[38;5;66;03m# Save RNG state\u001b[39;00m\n\u001b[1;32m   2361\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_rng_state(staging_output_dir)\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.11/site-packages/transformers/trainer.py:2462\u001b[0m, in \u001b[0;36mTrainer._save_optimizer_and_scheduler\u001b[0;34m(self, output_dir)\u001b[0m\n\u001b[1;32m   2457\u001b[0m     save_fsdp_optimizer(\n\u001b[1;32m   2458\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfsdp_plugin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, output_dir\n\u001b[1;32m   2459\u001b[0m     )\n\u001b[1;32m   2460\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[1;32m   2461\u001b[0m     \u001b[38;5;66;03m# deepspeed.save_checkpoint above saves model/optim/sched\u001b[39;00m\n\u001b[0;32m-> 2462\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOPTIMIZER_NAME\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2464\u001b[0m \u001b[38;5;66;03m# Save SCHEDULER & SCALER\u001b[39;00m\n\u001b[1;32m   2465\u001b[0m is_deepspeed_custom_scheduler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_deepspeed_enabled \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   2466\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler, DeepSpeedSchedulerWrapper\n\u001b[1;32m   2467\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.11/site-packages/torch/serialization.py:618\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    615\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 618\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.11/site-packages/torch/serialization.py:466\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 466\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_like\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_end_of_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    468\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:424] . unexpected pos 470625984 vs 470625872"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='/home/revo302/repos/CVE-Aanlysis-Project/results',          # output directory\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=2,   # batch size per device during training\n",
    "    per_device_eval_batch_size=2,    # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset, # defined previously\n",
    "    eval_dataset=validation_dataset, # define your validation dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
